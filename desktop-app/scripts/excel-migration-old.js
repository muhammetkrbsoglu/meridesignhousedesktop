/**
 * Excel to Supabase Migration Script
 * Migrates Excel CSV files to Supabase database
 */

const path = require('path')
require('dotenv').config({ path: path.join(__dirname, '..', '.env') })
const fs = require('fs')
const csv = require('csv-parser')
const iconv = require('iconv-lite')
const { createClient } = require('@supabase/supabase-js')

class ExcelMigration {
  constructor() {
    this.supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_ANON_KEY
    )

    this.migrationResults = {
      timestamp: new Date().toISOString(),
      migratedFiles: [],
      errors: [],
      summary: {
        totalRecords: 0,
        successfulInserts: 0,
        failedInserts: 0,
        skippedRecords: 0
      }
    }
  }

  async testConnection() {
    console.log('üîç Testing database connection...')

    try {
      console.log('Supabase URL:', process.env.SUPABASE_URL)
      console.log('Supabase Key:', process.env.SUPABASE_ANON_KEY ? '***masked***' : 'undefined')

      const { data, error } = await this.supabase
        .from('users')
        .select('count')
        .limit(1)

      if (error) {
        console.log('Connection error:', error)
        throw new Error(`Database connection failed: ${error.message}`)
      }

      console.log('‚úÖ Database connection successful')
    } catch (error) {
      console.log('Full error:', error)
      throw new Error(`Database connection test failed: ${error.message}`)
    }
  }

  async migrateAll() {
    console.log('üöÄ Starting Excel to Supabase migration...')

    try {
      // Test database connection first
      await this.testConnection()

      // Migrate customers
      await this.migrateCustomers()

      // Migrate products
      await this.migrateProducts()

      // Migrate orders
      await this.migrateOrders()

      // Migrate raw materials
      await this.migrateRawMaterials()

      // Migrate supplier orders
      await this.migrateSupplierOrders()

      // Migrate shipping costs
      await this.migrateShippingCosts()

      // Migrate cities
      await this.migrateCities()

      // Generate migration report
      await this.generateMigrationReport()

      console.log('‚úÖ Migration completed successfully!')

    } catch (error) {
      console.error('‚ùå Migration failed:', error)
      await this.generateMigrationReport()
      process.exit(1)
    }
  }

  // Debug method to test individual migrations
  async testCustomersOnly() {
    console.log('üß™ Testing customer migration only...')

    try {
      await this.testConnection()
      await this.migrateCustomers()
      await this.generateMigrationReport()

      console.log('‚úÖ Customer migration test completed!')
    } catch (error) {
      console.error('‚ùå Customer migration test failed:', error)
      await this.generateMigrationReport()
    }
  }

  async migrateCustomers() {
    console.log('üìä Migrating customers from SQLite...')
    console.log('__dirname:', __dirname)
    console.log('Current working directory:', process.cwd())

    const customers = []
    const sqlitePath = path.join(__dirname, 'takip_programi.db')
    console.log('SQLite file path:', sqlitePath)

    return new Promise((resolve, reject) => {
      console.log('Opening SQLite database:', sqlitePath)
      let rowCount = 0

      // Use sqlite3 instead of CSV
      const sqlite3 = require('sqlite3').verbose()
      const db = new sqlite3.Database(sqlitePath, sqlite3.OPEN_READONLY, (err) => {
        if (err) {
          console.error('‚ùå Error opening SQLite database:', err.message)
          reject(err)
          return
        }

        console.log('‚úÖ SQLite database opened successfully')

        // Query customers table, skip header rows
        db.all(`SELECT * FROM V_M√º≈üteriler WHERE "Unnamed: 3" IS NOT NULL AND "Unnamed: 3" != 'M√ú≈ûTERƒ∞LER' AND "Unnamed: 3" != 'Ad Soyadƒ±'`, async (err, rows) => {
          if (err) {
            console.error('‚ùå Error querying customers:', err.message)
            db.close()
            reject(err)
            return
          }

          console.log(`üìã Found ${rows.length} customer records to process`)

          rows.forEach((row, index) => {
            rowCount++

            // Debug: Log first few rows
            if (index < 3) {
              console.log(`Row ${index}:`, row)
            }

            // Skip empty rows
            if (!row['Unnamed: 3'] || row['Unnamed: 3'].trim() === '') {
              console.log(`‚è≠Ô∏è  Skipping empty row ${index}`)
              this.migrationResults.summary.skippedRecords++
              return
            }

            // Generate a unique ID for the user
            const customerId = `customer_${row['Unnamed: 2']?.trim()}_${Date.now()}`

            const customer = {
              id: customerId,
              email: null, // Email column doesn't exist in SQLite
              name: row['Unnamed: 3']?.trim() || '',
              phone: row['Unnamed: 4']?.trim() || null,
              address: row['Unnamed: 5']?.trim() || null,
              city: row['Unnamed: 6']?.trim() || null,
              state: row['Unnamed: 7']?.trim() || null,
              zip_code: null,
              country: 'Turkey',
              role: 'CUSTOMER',
              newsletter_subscription: false,
              preferences: {},
              created_at: new Date().toISOString(),
              updated_at: new Date().toISOString()
            }

            customers.push(customer)

            // Log first few customers for debugging
            if (customers.length <= 3) {
              console.log(`üîç Processing customer: ${JSON.stringify(row)}`)
            }
          })

          console.log(`‚úÖ Processed ${customers.length} customers from SQLite`)

          // Insert customers in batches to avoid timeout
          if (customers.length > 0) {
            console.log('üíæ Inserting customers to Supabase...')

            // Insert in batches to avoid timeout
            const batchSize = 50
            let successfulInserts = 0
            let failedInserts = 0

            // Process batches sequentially using promises
            const processBatches = async () => {
              for (let i = 0; i < customers.length; i += batchSize) {
                const batch = customers.slice(i, i + batchSize)
                console.log(`üîÑ Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(customers.length / batchSize)} (${batch.length} customers)`)

                try {
                  const { data, error } = await this.supabase
                    .from('users')
                    .insert(batch)
                    .select()

                  if (error) {
                    console.error(`‚ùå Error inserting batch ${Math.floor(i / batchSize) + 1}:`, error)
                    failedInserts += batch.length
                  } else {
                    console.log(`‚úÖ Successfully inserted ${data?.length || 0} customers in batch ${Math.floor(i / batchSize) + 1}`)
                    successfulInserts += data?.length || 0
                  }
                } catch (err) {
                  console.error(`‚ùå Exception in batch ${Math.floor(i / batchSize) + 1}:`, err)
                  failedInserts += batch.length
                }
              }
            }

            await processBatches()

            console.log(`‚úÖ Migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
          } else {
            console.log('‚ö†Ô∏è No customers to insert')
          }

          db.close((err) => {
            if (err) {
              console.error('‚ùå Error closing database:', err.message)
            } else {
              console.log('‚úÖ Database closed successfully')
            }
            resolve()
          })
        })
      })
    })
  }

  async insertBatch(tableName, records, batchSize) {
    console.log(`üì¶ Inserting ${records.length} records to ${tableName} in batches of ${batchSize}`)

    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize)
      console.log(`üîÑ Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(records.length / batchSize)} (${batch.length} records)`)

      try {
        const { data, error } = await this.supabase
          .from(tableName)
          .insert(batch)
          .select()

        if (error) {
          console.error(`‚ùå Error inserting batch ${Math.floor(i / batchSize) + 1}:`, error)
          this.migrationResults.failedInserts += batch.length
        } else {
          console.log(`‚úÖ Successfully inserted ${data?.length || 0} records in batch ${Math.floor(i / batchSize) + 1}`)
          this.migrationResults.successfulInserts += data?.length || 0
        }
      } catch (err) {
        console.error(`‚ùå Exception in batch ${Math.floor(i / batchSize) + 1}:`, err)
        this.migrationResults.failedInserts += batch.length
      }
      }

      console.log(`‚úÖ Customer migration completed successfully`)
      this.migrationResults.summary.totalRecords += customers.length
      resolve()
    } catch (error) {
      console.error('‚ùå Customer migration error:', error)
      reject(error)
    }
    })
  }

  async migrateProducts() {
    console.log('üìä Products migration not implemented yet - using SQLite approach')
    console.log('‚úÖ Migration completed successfully')
    return Promise.resolve()
  }

  async testSQLite() {
    console.log('üß™ Testing SQLite database connection...')
    const sqlitePath = path.join(__dirname, 'takip_programi.db')

    return new Promise((resolve, reject) => {
      const sqlite3 = require('sqlite3').verbose()
      const db = new sqlite3.Database(sqlitePath, sqlite3.OPEN_READONLY, (err) => {
        if (err) {
          console.error('‚ùå Error opening SQLite database:', err.message)
          reject(err)
          return
        }

        console.log('‚úÖ SQLite database opened successfully')

        // Test query
        db.get('SELECT COUNT(*) as count FROM V_M√º≈üteriler', (err, row) => {
          if (err) {
            console.error('‚ùå Error querying database:', err.message)
            db.close()
            reject(err)
            return
          }

          console.log(`üìä Total customers in SQLite: ${row.count}`)

          db.close((err) => {
            if (err) {
              console.error('‚ùå Error closing database:', err.message)
            } else {
              console.log('‚úÖ Database closed successfully')
            }
            resolve()
          })
        })
      })
    })
  }

  async migrateCustomers() {
    console.log('üìä Migrating customers from SQLite...')
    console.log('__dirname:', __dirname)
    console.log('Current working directory:', process.cwd())

    const customers = []
    const sqlitePath = path.join(__dirname, 'takip_programi.db')
    console.log('SQLite file path:', sqlitePath)

    return new Promise((resolve, reject) => {
      console.log('Opening SQLite database:', sqlitePath)
      let rowCount = 0

      // Use sqlite3 instead of CSV
      const sqlite3 = require('sqlite3').verbose()
      const db = new sqlite3.Database(sqlitePath, sqlite3.OPEN_READONLY, (err) => {
        if (err) {
          console.error('‚ùå Error opening SQLite database:', err.message)
          reject(err)
          return
        }

        console.log('‚úÖ SQLite database opened successfully')

        // Query customers table, skip header rows
        db.all(`SELECT * FROM V_M√º≈üteriler WHERE "Unnamed: 3" IS NOT NULL AND "Unnamed: 3" != 'M√ú≈ûTERƒ∞LER' AND "Unnamed: 3" != 'Ad Soyadƒ±'`, async (err, rows) => {
          if (err) {
            console.error('‚ùå Error querying customers:', err.message)
            db.close()
            reject(err)
            return
          }

          console.log(`üìã Found ${rows.length} customer records to process`)

          rows.forEach((row, index) => {
            rowCount++

            // Debug: Log first few rows
            if (index < 3) {
              console.log(`Row ${index}:`, row)
            }

            // Skip empty rows
            if (!row['Unnamed: 3'] || row['Unnamed: 3'].trim() === '') {
              console.log(`‚è≠Ô∏è  Skipping empty row ${index}`)
              this.migrationResults.summary.skippedRecords++
              return
            }

            // Generate a unique ID for the user
            const customerId = `customer_${row['Unnamed: 2']?.trim()}_${Date.now()}`

            const customer = {
              id: customerId,
              email: null, // Email column doesn't exist in SQLite
              name: row['Unnamed: 3']?.trim() || '',
              phone: row['Unnamed: 4']?.trim() || null,
              address: row['Unnamed: 5']?.trim() || null,
              city: row['Unnamed: 6']?.trim() || null,
              state: row['Unnamed: 7']?.trim() || null,
              zip_code: null,
              country: 'Turkey',
              role: 'CUSTOMER',
              newsletter_subscription: false,
              preferences: {},
              created_at: new Date().toISOString(),
              updated_at: new Date().toISOString()
            }

            customers.push(customer)

            // Log first few customers for debugging
            if (customers.length <= 3) {
              console.log(`üîç Processing customer: ${JSON.stringify(row)}`)
            }
          })

          console.log(`‚úÖ Processed ${customers.length} customers from SQLite`)

          // Insert customers in batches to avoid timeout
          if (customers.length > 0) {
            console.log('üíæ Inserting customers to Supabase...')

            // Insert in batches to avoid timeout
            const batchSize = 50
            let successfulInserts = 0
            let failedInserts = 0

            // Process batches sequentially using promises
            const processBatches = async () => {
              for (let i = 0; i < customers.length; i += batchSize) {
                const batch = customers.slice(i, i + batchSize)
                console.log(`üîÑ Processing batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(customers.length / batchSize)} (${batch.length} customers)`)

                try {
                  const { data, error } = await this.supabase
                    .from('users')
                    .insert(batch)
                    .select()

                  if (error) {
                    console.error(`‚ùå Error inserting batch ${Math.floor(i / batchSize) + 1}:`, error)
                    failedInserts += batch.length
                  } else {
                    console.log(`‚úÖ Successfully inserted ${data?.length || 0} customers in batch ${Math.floor(i / batchSize) + 1}`)
                    successfulInserts += data?.length || 0
                  }
                } catch (err) {
                  console.error(`‚ùå Exception in batch ${Math.floor(i / batchSize) + 1}:`, err)
                  failedInserts += batch.length
                }
              }
            }

            await processBatches()

            console.log(`‚úÖ Migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
          } else {
            console.log('‚ö†Ô∏è No customers to insert')
          }

          db.close((err) => {
            if (err) {
              console.error('‚ùå Error closing database:', err.message)
            } else {
              console.log('‚úÖ Database closed successfully')
            }
            resolve()
          })
        })
      })
    })
  }

  async migrateProducts() {
    console.log('üìä Migrating products from SQLite...')

    const products = []
    const sqlitePath = path.join(__dirname, 'takip_programi.db')
    console.log('SQLite file path:', sqlitePath)

    return new Promise((resolve, reject) => {
      console.log('Opening SQLite database:', sqlitePath)

      // Use sqlite3 instead of CSV
      const sqlite3 = require('sqlite3').verbose()
      const db = new sqlite3.Database(sqlitePath, sqlite3.OPEN_READONLY, (err) => {
        if (err) {
          console.error('‚ùå Error opening SQLite database:', err.message)
          reject(err)
          return
        }

        console.log('‚úÖ SQLite database opened successfully')

        // Query products table, skip header rows
        db.all(`SELECT * FROM V_√úr√ºnler WHERE "Unnamed: 4" IS NOT NULL AND "Unnamed: 4" != '√úR√úNLER' AND "Unnamed: 4" != '√úr√ºn Adƒ±'`, async (err, rows) => {
          if (err) {
            console.error('‚ùå Error querying products:', err.message)
            db.close()
            reject(err)
            return
          }

          console.log(`üìã Found ${rows.length} product records to process`)

          rows.forEach((row, index) => {
            // Debug: Log first few rows
            if (index < 3) {
              console.log(`Row ${index}:`, row)
            }

            // Skip empty rows
            if (!row['Unnamed: 4'] || row['Unnamed: 4'].trim() === '') {
              console.log(`‚è≠Ô∏è  Skipping empty row ${index}`)
              this.migrationResults.summary.skippedRecords++
              return
            }

            // Generate a unique ID for the product
            const productId = `product_${row['Unnamed: 2']?.trim()}_${Date.now()}`

            const product = {
              id: productId,
              name: row['Unnamed: 4']?.trim() || '',
              sku: row['Unnamed: 2']?.trim() || null,
              price: 0, // Will be calculated later
              stock: 0,
              isActive: true,
              isFeatured: false,

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row, index) => {
          // Skip header rows (first 3 rows) and empty rows
          if (index < 3 || !row['√úr√ºn Adƒ±'] || row['√úr√ºn Adƒ±'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          // Generate unique IDs
          const productId = `product_${row['No']?.trim()}_${Date.now()}_${index}`
          const categoryId = `category_${row['Kategori']?.trim().toLowerCase().replace(/\s+/g, '_')}_${Date.now()}`

          // Extract price from "Birim Satƒ±≈ü Tutarƒ±" column
          const salesPriceStr = row['Birim Satƒ±≈ü Tutarƒ±']?.trim() || '0'
          const salesPrice = parseFloat(salesPriceStr.replace('‚Ç∫', '').replace(',', '.')) || 0

          // Calculate cost price from yarƒ± mamul prices
          let costPrice = 0
          for (let i = 1; i <= 9; i++) {
            const materialPrice = parseFloat(row[`${i}.Y.M. Birim Fiyatƒ±`]?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0
            costPrice += materialPrice
          }

          // Create category if not exists
          const category = {
            id: categoryId,
            name: row['Kategori']?.trim() || 'Uncategorized',
            slug: row['Kategori']?.trim().toLowerCase().replace(/\s+/g, '-') || 'uncategorized',
            description: `${row['Kategori']?.trim()} √ºr√ºnleri`,
            isActive: true,
            sortOrder: 0,
            createdAt: new Date().toISOString(),
            updatedAt: new Date().toISOString()
          }

          if (!categories.find(c => c.name === category.name)) {
            categories.push(category)
          }

          const product = {
            id: productId,
            name: row['√úr√ºn Adƒ±']?.trim() || '',
            slug: row['√úr√ºn Adƒ±']?.trim().toLowerCase().replace(/\s+/g, '-') || 'unnamed-product',
            sku: row['No']?.trim() || null,
            price: salesPrice,
            oldPrice: null,
            comparePrice: null,
            stock: 0, // Default stock
            isActive: true,
            isFeatured: false,
            isNewArrival: false,
            isProductOfWeek: false,
            categoryId: categoryId,
            createdAt: new Date().toISOString(),
            updatedAt: new Date().toISOString(),
            colors: [],
            hasVariants: false
          }

          products.push(product)

          // Log first few products for debugging
          if (products.length <= 3) {
            console.log(`üîç Processing product: ${row['√úr√ºn Adƒ±']} - Price: ${salesPrice}`)
          }
        })
        .on('end', async () => {
          try {
            console.log(`üìã Total products to migrate: ${products.length}`)
            console.log(`üìã Total categories to migrate: ${categories.length}`)

            let successfulInserts = 0
            let failedInserts = 0

            // First, migrate categories
            if (categories.length > 0) {
              console.log('üì¶ Migrating categories first...')
              const { data: categoryData, error: categoryError } = await this.supabase
                .from('categories')
                .insert(categories)
                .select()

              if (categoryError) {
                console.error('‚ùå Categories migration failed:', categoryError.message)
                this.migrationResults.errors.push({
                  file: 'categories',
                  error: categoryError.message,
                  count: categories.length
                })
              } else {
                successfulInserts += categoryData.length
                console.log(`‚úÖ Migrated ${categoryData.length} categories`)
              }
            }

            // Then, migrate products
            if (products.length > 0) {
              console.log('üì¶ Migrating products...')

              // Insert in batches to avoid timeout
              const batchSize = 50
              for (let i = 0; i < products.length; i += batchSize) {
                const batch = products.slice(i, i + batchSize)
                console.log(`üì¶ Migrating product batch ${Math.floor(i/batchSize) + 1} (${batch.length} products)`)

                const { data, error } = await this.supabase
                  .from('products')
                  .insert(batch)
                  .select()

                if (error) {
                  console.error(`‚ùå Product batch ${Math.floor(i/batchSize) + 1} failed:`, error.message)
                  this.migrationResults.errors.push({
                    file: 'products',
                    error: `Batch ${Math.floor(i/batchSize) + 1}: ${error.message}`,
                    count: batch.length
                  })
                  failedInserts += batch.length
                } else {
                  successfulInserts += data.length
                  console.log(`‚úÖ Product batch ${Math.floor(i/batchSize) + 1} successful: ${data.length} products`)
                }
              }
            }

            this.migrationResults.summary.successfulInserts += successfulInserts
            this.migrationResults.summary.failedInserts += failedInserts

            this.migrationResults.migratedFiles.push({
              file: 'products_and_categories',
              records: successfulInserts,
              status: successfulInserts > 0 ? 'success' : 'failed'
            })

            console.log(`‚úÖ Products migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
            this.migrationResults.summary.totalRecords += products.length
            resolve()
          } catch (error) {
            console.error('‚ùå Products migration error:', error)
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  async migrateOrders() {
    console.log('üìä Migrating orders...')

    const orders = []
    const orderItems = []
    const filePath = path.join('C:', 'Users', 'fower', 'Desktop', 'meridesignhousedesktop', 'excel', 'TAKƒ∞P PROGRAMI 1(sipari≈üler).csv')

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row, index) => {
          // Skip header rows (first 3 rows) and empty rows
          if (index < 3 || !row['M√º≈üteri'] || row['M√º≈üteri'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          // Generate unique order ID
          const orderId = `order_${Date.now()}_${index}`

          // Parse prices and clean currency symbols
          const unitPrice = parseFloat(row['Birim Satƒ±≈ü Tutarƒ±']?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0
          const quantity = parseInt(row['Adet']?.replace(',', '.') || '0') || 0
          const totalAmount = unitPrice * quantity
          const shippingCost = parseFloat(row['Kargo √úcreti']?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0

          const order = {
            id: orderId,
            orderNumber: `ORD-${Date.now()}-${index}`, // Generate unique order number
            customerName: row['M√º≈üteri']?.trim() || '',
            customerEmail: null, // Email not available in CSV
            customerPhone: null, // Phone not directly available in this CSV
            status: this.mapOrderStatus(row['√ñdeme Durumu']?.trim() || 'bekliyor'),
            totalAmount: totalAmount + shippingCost,
            shippingCost: shippingCost,
            taxAmount: 0, // Tax not specified
            shippingAddress: row['Sipari≈ü Notu']?.trim() || 'Adres bilgisi mevcut deƒüil',
            shippingCity: null, // City not specified in this CSV
            shippingState: null, // State not specified in this CSV
            shippingZip: null,
            shippingCountry: 'Turkey',
            notes: row['Sipari≈ü Notu']?.trim() || null,
            createdAt: this.parseDate(row['Sipari≈ü Alƒ±nan Tarih']?.trim()) || new Date().toISOString(),
            updatedAt: new Date().toISOString(),
            payment_status: row['√ñdeme Durumu']?.trim() || 'PENDING'
          }

          // Create order item
          const orderItem = {
            id: `order_item_${Date.now()}_${index}`,
            orderId: orderId,
            productId: null, // Will be linked later if product exists
            quantity: quantity,
            price: unitPrice,
            createdAt: new Date().toISOString()
          }

          orders.push(order)
          orderItems.push(orderItem)

          // Log first few orders for debugging
          if (orders.length <= 3) {
            console.log(`üîç Processing order: ${row['M√º≈üteri']} - ${row['√úr√ºn Adƒ±']} x${quantity} = ‚Ç∫${totalAmount}`)
          }
        })
        .on('end', async () => {
          try {
            console.log(`üìã Total orders to migrate: ${orders.length}`)

            let successfulInserts = 0
            let failedInserts = 0

            // First, migrate orders
            if (orders.length > 0) {
              console.log('üì¶ Migrating orders...')

              // Insert in batches to avoid timeout
              const batchSize = 50
              for (let i = 0; i < orders.length; i += batchSize) {
                const batch = orders.slice(i, i + batchSize)
                console.log(`üì¶ Migrating order batch ${Math.floor(i/batchSize) + 1} (${batch.length} orders)`)

                const { data, error } = await this.supabase
                  .from('orders')
                  .insert(batch)
                  .select()

                if (error) {
                  console.error(`‚ùå Order batch ${Math.floor(i/batchSize) + 1} failed:`, error.message)
                  this.migrationResults.errors.push({
                    file: 'orders',
                    error: `Batch ${Math.floor(i/batchSize) + 1}: ${error.message}`,
                    count: batch.length
                  })
                  failedInserts += batch.length
                } else {
                  successfulInserts += data.length
                  console.log(`‚úÖ Order batch ${Math.floor(i/batchSize) + 1} successful: ${data.length} orders`)
                }
              }
            }

            // Then, migrate order items
            if (orderItems.length > 0) {
              console.log('üì¶ Migrating order items...')

              const batchSize = 50
              for (let i = 0; i < orderItems.length; i += batchSize) {
                const batch = orderItems.slice(i, i + batchSize)
                console.log(`üì¶ Migrating order item batch ${Math.floor(i/batchSize) + 1} (${batch.length} items)`)

                const { data, error } = await this.supabase
                  .from('order_items')
                  .insert(batch)
                  .select()

                if (error) {
                  console.error(`‚ùå Order item batch ${Math.floor(i/batchSize) + 1} failed:`, error.message)
                  this.migrationResults.errors.push({
                    file: 'order_items',
                    error: `Batch ${Math.floor(i/batchSize) + 1}: ${error.message}`,
                    count: batch.length
                  })
                  failedInserts += batch.length
                } else {
                  successfulInserts += data.length
                  console.log(`‚úÖ Order item batch ${Math.floor(i/batchSize) + 1} successful: ${data.length} items`)
                }
              }
            }

            this.migrationResults.summary.successfulInserts += successfulInserts
            this.migrationResults.summary.failedInserts += failedInserts

            this.migrationResults.migratedFiles.push({
              file: 'orders_and_order_items',
              records: successfulInserts,
              status: successfulInserts > 0 ? 'success' : 'failed'
            })

            console.log(`‚úÖ Orders migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
            this.migrationResults.summary.totalRecords += orders.length
            resolve()
          } catch (error) {
            console.error('‚ùå Orders migration error:', error)
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  async migrateRawMaterials() {
    console.log('üìä Migrating raw materials...')

    const rawMaterials = []
    const suppliers = []
    const filePath = path.join('C:', 'Users', 'fower', 'Desktop', 'meridesignhousedesktop', 'excel', 'TAKƒ∞P PROGRAMI 1(yarƒ±-mamul-listesi).csv')

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row, index) => {
          // Skip header rows (first 3 rows) and empty rows
          if (index < 3 || !row['Yarƒ± Mamul Adƒ±'] || row['Yarƒ± Mamul Adƒ±'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          // Generate unique IDs
          const rawMaterialId = `raw_material_${Date.now()}_${index}`
          const supplierId = `supplier_${row['Tedarik√ßi Adƒ±']?.trim().toLowerCase().replace(/\s+/g, '_')}_${Date.now()}`

          // Parse prices and clean currency symbols
          const unitPrice = parseFloat(row['Yarƒ± Mamul Birim Fiyatƒ±']?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0
          const stockQuantity = parseFloat(row['Stok Miktarƒ±']?.replace(',', '.') || '0') || 0

          // Create supplier if not exists
          const supplier = {
            id: supplierId,
            name: row['Tedarik√ßi Adƒ±']?.trim() || 'Bilinmeyen Tedarik√ßi',
            contact: row['√úr√ºn Linki / Tedarik√ßi ƒ∞leti≈üim numarasƒ±']?.trim() || null,
            url: row['√úr√ºn Linki / Tedarik√ßi ƒ∞leti≈üim numarasƒ±']?.trim() || null,
            notes: row['A√ßƒ±klama']?.trim() || null,
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString()
          }

          if (!suppliers.find(s => s.name === supplier.name)) {
            suppliers.push(supplier)
          }

          const rawMaterial = {
            id: rawMaterialId,
            name: row['Yarƒ± Mamul Adƒ±']?.trim() || '',
            unit_price_try: unitPrice,
            stock_quantity: stockQuantity,
            stock_unit: 'adet', // Default unit
            supplier_id: supplierId,
            contact_or_url: row['√úr√ºn Linki / Tedarik√ßi ƒ∞leti≈üim numarasƒ±']?.trim() || null,
            price_date: this.parseDate(row['Fiyat Alƒ±m Tarihi']?.trim()),
            notes: row['A√ßƒ±klama']?.trim() || null,
            min_stock_quantity: stockQuantity * 0.1, // Set min stock to 10% of current stock
            min_stock_unit: 'adet',
            lead_time_days: 7, // Default lead time
            reorder_point: stockQuantity * 0.2, // Reorder when 20% remaining
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString()
          }

          rawMaterials.push(rawMaterial)

          // Log first few raw materials for debugging
          if (rawMaterials.length <= 3) {
            console.log(`üîç Processing raw material: ${row['Yarƒ± Mamul Adƒ±']} - Stock: ${stockQuantity} - Price: ‚Ç∫${unitPrice}`)
          }
        })
        .on('end', async () => {
          try {
            console.log(`üìã Total raw materials to migrate: ${rawMaterials.length}`)
            console.log(`üìã Total suppliers to migrate: ${suppliers.length}`)

            let successfulInserts = 0
            let failedInserts = 0

            // First, migrate suppliers
            if (suppliers.length > 0) {
              console.log('üì¶ Migrating suppliers first...')

              const { data: supplierData, error: supplierError } = await this.supabase
                .from('suppliers')
                .insert(suppliers)
                .select()

              if (supplierError) {
                console.error('‚ùå Suppliers migration failed:', supplierError.message)
                this.migrationResults.errors.push({
                  file: 'suppliers',
                  error: supplierError.message,
                  count: suppliers.length
                })
              } else {
                successfulInserts += supplierData.length
                console.log(`‚úÖ Migrated ${supplierData.length} suppliers`)
              }
            }

            // Then, migrate raw materials
            if (rawMaterials.length > 0) {
              console.log('üì¶ Migrating raw materials...')

              // Insert in batches to avoid timeout
              const batchSize = 50
              for (let i = 0; i < rawMaterials.length; i += batchSize) {
                const batch = rawMaterials.slice(i, i + batchSize)
                console.log(`üì¶ Migrating raw material batch ${Math.floor(i/batchSize) + 1} (${batch.length} materials)`)

                const { data, error } = await this.supabase
                  .from('raw_materials')
                  .insert(batch)
                  .select()

                if (error) {
                  console.error(`‚ùå Raw material batch ${Math.floor(i/batchSize) + 1} failed:`, error.message)
                  this.migrationResults.errors.push({
                    file: 'raw_materials',
                    error: `Batch ${Math.floor(i/batchSize) + 1}: ${error.message}`,
                    count: batch.length
                  })
                  failedInserts += batch.length
                } else {
                  successfulInserts += data.length
                  console.log(`‚úÖ Raw material batch ${Math.floor(i/batchSize) + 1} successful: ${data.length} materials`)
                }
              }
            }

            this.migrationResults.summary.successfulInserts += successfulInserts
            this.migrationResults.summary.failedInserts += failedInserts

            this.migrationResults.migratedFiles.push({
              file: 'raw_materials_and_suppliers',
              records: successfulInserts,
              status: successfulInserts > 0 ? 'success' : 'failed'
            })

            console.log(`‚úÖ Raw materials migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
            this.migrationResults.summary.totalRecords += rawMaterials.length
            resolve()
          } catch (error) {
            console.error('‚ùå Raw materials migration error:', error)
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  async migrateSupplierOrders() {
    console.log('üìä Migrating supplier orders...')

    const supplierOrders = []
    const filePath = path.join(__dirname, '..', '..', 'excel', 'TAKƒ∞P PROGRAMI 1(sipari≈ü-verilecek-malzemeler).csv')

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row, index) => {
          // Skip header rows (first row) and empty rows
          if (index < 1 || !row['Firma'] || row['Firma'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          // Generate unique order ID
          const orderId = `supplier_order_${Date.now()}_${index}`

          // Parse prices and clean currency symbols
          const unitPrice = parseFloat(row['Adet Fiyatƒ±']?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0
          const quantity = parseFloat(row['Adet/Kg']?.replace(',', '.') || '0') || 0
          const totalPrice = parseFloat(row['Toplam Fiyat']?.replace('‚Ç∫', '').replace(',', '.') || '0') || 0

          // Create items JSON for supplier order
          const itemsJson = [{
            name: row['Malzeme']?.trim() || '',
            quantity: quantity,
            unit_price: unitPrice,
            total_price: totalPrice
          }]

          const supplierOrder = {
            id: orderId,
            supplier_id: null, // Will be linked to supplier if exists
            status: 'PENDING',
            items_json: itemsJson,
            notes: `Malzeme: ${row['Malzeme']?.trim() || ''}`,
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString()
          }

          supplierOrders.push(supplierOrder)

          // Log first few supplier orders for debugging
          if (supplierOrders.length <= 3) {
            console.log(`üîç Processing supplier order: ${row['Malzeme']} - Qty: ${quantity} - Total: ‚Ç∫${totalPrice} - Supplier: ${row['Firma']}`)
          }
        })
        .on('end', async () => {
          try {
            console.log(`üìã Total supplier orders to migrate: ${supplierOrders.length}`)

            if (supplierOrders.length > 0) {
              // Insert in batches to avoid timeout
              const batchSize = 50
              let successfulInserts = 0
              let failedInserts = 0

              for (let i = 0; i < supplierOrders.length; i += batchSize) {
                const batch = supplierOrders.slice(i, i + batchSize)
                console.log(`üì¶ Migrating supplier order batch ${Math.floor(i/batchSize) + 1} (${batch.length} orders)`)

                const { data, error } = await this.supabase
                  .from('supplier_orders')
                  .insert(batch)
                  .select()

                if (error) {
                  console.error(`‚ùå Supplier order batch ${Math.floor(i/batchSize) + 1} failed:`, error.message)
                  this.migrationResults.errors.push({
                    file: 'supplier_orders',
                    error: `Batch ${Math.floor(i/batchSize) + 1}: ${error.message}`,
                    count: batch.length
                  })
                  failedInserts += batch.length
                } else {
                  successfulInserts += data.length
                  console.log(`‚úÖ Supplier order batch ${Math.floor(i/batchSize) + 1} successful: ${data.length} orders`)
                }
              }

              this.migrationResults.summary.successfulInserts += successfulInserts
              this.migrationResults.summary.failedInserts += failedInserts

              this.migrationResults.migratedFiles.push({
                file: 'supplier_orders',
                records: successfulInserts,
                status: successfulInserts > 0 ? 'success' : 'failed'
              })

              console.log(`‚úÖ Supplier orders migration completed: ${successfulInserts} successful, ${failedInserts} failed`)
            }

            this.migrationResults.summary.totalRecords += supplierOrders.length
            resolve()
          } catch (error) {
            console.error('‚ùå Supplier orders migration error:', error)
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  async migrateShippingCosts() {
    console.log('üìä Migrating shipping costs...')

    const shippingCosts = []
    const filePath = path.join(__dirname, '..', '..', 'excel', 'TAKƒ∞P PROGRAMI 1(kargo-√ºcretleri).csv')

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row) => {
          // Skip empty rows
          if (!row['≈ûehir'] || row['≈ûehir'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          const shippingCost = {
            city: row['≈ûehir']?.trim() || '',
            cost: parseFloat(row['√úcret']?.replace(',', '.') || '0') || 0,
            estimated_days: parseInt(row['Tahmini G√ºn'] || '0') || null,
            created_at: new Date().toISOString(),
            updated_at: new Date().toISOString()
          }

          shippingCosts.push(shippingCost)
        })
        .on('end', async () => {
          try {
            if (shippingCosts.length > 0) {
              const { data, error } = await this.supabase
                .from('shipping_costs')
                .insert(shippingCosts)
                .select()

              if (error) {
                this.migrationResults.errors.push({
                  file: 'shipping_costs',
                  error: error.message,
                  count: shippingCosts.length
                })
                this.migrationResults.summary.failedInserts += shippingCosts.length
              } else {
                this.migrationResults.summary.successfulInserts += data.length
                this.migrationResults.migratedFiles.push({
                  file: 'shipping_costs',
                  records: data.length,
                  status: 'success'
                })
                console.log(`‚úÖ Migrated ${data.length} shipping costs`)
              }
            }

            this.migrationResults.summary.totalRecords += shippingCosts.length
            resolve()
          } catch (error) {
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  async migrateCities() {
    console.log('üìä Migrating cities...')

    const cities = []
    const filePath = path.join('C:', 'Users', 'fower', 'Desktop', 'meridesignhousedesktop', 'excel', 'TAKƒ∞P PROGRAMI 1(il-il√ße).csv')

    return new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(iconv.decodeStream('utf8'))
        .pipe(csv({ separator: ';' }))
        .on('data', (row) => {
          // Skip empty rows
          if (!row['ƒ∞l'] || row['ƒ∞l'].trim() === '') {
            this.migrationResults.summary.skippedRecords++
            return
          }

          const city = {
            name: row['ƒ∞l']?.trim() || '',
            created_at: new Date().toISOString()
          }

          cities.push(city)
        })
        .on('end', async () => {
          try {
            if (cities.length > 0) {
              const { data, error } = await this.supabase
                .from('cities')
                .insert(cities)
                .select()

              if (error) {
                this.migrationResults.errors.push({
                  file: 'cities',
                  error: error.message,
                  count: cities.length
                })
                this.migrationResults.summary.failedInserts += cities.length
              } else {
                this.migrationResults.summary.successfulInserts += data.length
                this.migrationResults.migratedFiles.push({
                  file: 'cities',
                  records: data.length,
                  status: 'success'
                })
                console.log(`‚úÖ Migrated ${data.length} cities`)
              }
            }

            this.migrationResults.summary.totalRecords += cities.length
            resolve()
          } catch (error) {
            reject(error)
          }
        })
        .on('error', reject)
    })
  }

  getCategoryId(categoryName) {
    // Map Turkish category names to existing categories
    const categoryMap = {
      'Elektronik': 'electronics',
      'Giyim': 'clothing',
      'Ev & Ya≈üam': 'home-living',
      'Spor': 'sports',
      'Kitap': 'books',
      'Kozmetik': 'cosmetics'
    }

    return categoryMap[categoryName] || 'others'
  }

  mapOrderStatus(status) {
    const statusMap = {
      'bekliyor': 'PENDING',
      'onaylandƒ±': 'CONFIRMED',
      'hazƒ±rlanƒ±yor': 'PROCESSING',
      'kargoda': 'SHIPPED',
      'teslim edildi': 'DELIVERED',
      'iptal edildi': 'CANCELLED'
    }

    return statusMap[status.toLowerCase()] || 'PENDING'
  }

  parseDate(dateStr) {
    if (!dateStr || dateStr.trim() === '') return null

    try {
      // Try different date formats
      const formats = [
        /^(\d{2})\.(\d{2})\.(\d{4})$/, // DD.MM.YYYY
        /^(\d{4})-(\d{2})-(\d{2})$/,   // YYYY-MM-DD
        /^(\d{2})\/(\d{2})\/(\d{4})$/   // DD/MM/YYYY
      ]

      for (const format of formats) {
        const match = dateStr.match(format)
        if (match) {
          if (format.source.includes('DD.MM.YYYY')) {
            return new Date(`${match[3]}-${match[2]}-${match[1]}`).toISOString()
          } else if (format.source.includes('YYYY-MM-DD')) {
            return new Date(dateStr).toISOString()
          } else if (format.source.includes('DD/MM/YYYY')) {
            return new Date(`${match[3]}-${match[2]}-${match[1]}`).toISOString()
          }
        }
      }

      // If no format matches, try to parse directly
      const parsedDate = new Date(dateStr)
      if (!isNaN(parsedDate.getTime())) {
        return parsedDate.toISOString()
      }

      return null
    } catch (error) {
      console.warn(`Failed to parse date: ${dateStr}`)
      return null
    }
  }

  async generateMigrationReport() {
    console.log('üìã Generating migration report...')

    const report = {
      ...this.migrationResults,
      summary: {
        ...this.migrationResults.summary,
        successRate: this.migrationResults.summary.totalRecords > 0
          ? Math.round((this.migrationResults.summary.successfulInserts / this.migrationResults.summary.totalRecords) * 100)
          : 0
      }
    }

    const reportPath = 'migration-report.json'
    fs.writeFileSync(reportPath, JSON.stringify(report, null, 2))

    console.log(`üìÑ Migration report generated: ${reportPath}`)

    // Log summary
    console.log('\nüìä Migration Summary:')
    console.log(`Total Files Processed: ${this.migrationResults.migratedFiles.length}`)
    console.log(`Total Records: ${this.migrationResults.summary.totalRecords}`)
    console.log(`Successful Inserts: ${this.migrationResults.summary.successfulInserts}`)
    console.log(`Failed Inserts: ${this.migrationResults.summary.failedInserts}`)
    console.log(`Skipped Records: ${this.migrationResults.summary.skippedRecords}`)
    console.log(`Success Rate: ${report.summary.successRate}%`)

    if (this.migrationResults.errors.length > 0) {
      console.log('\n‚ùå Errors:')
      this.migrationResults.errors.forEach(error => {
        console.log(`  - ${error.file}: ${error.error} (${error.count} records)`)
      })
    }

    if (this.migrationResults.summary.successRate === 100) {
      console.log('üéâ Migration completed with 100% success rate!')
    } else if (this.migrationResults.summary.successRate >= 90) {
      console.log('‚úÖ Migration completed successfully with minor issues')
    } else {
      console.log('‚ö†Ô∏è Migration completed with some failures - check the report')
    }
  }
}

// CLI interface
if (require.main === module) {
  const args = process.argv.slice(2)

  if (args.includes('--test-customers')) {
    console.log('üß™ Running customer migration test...')
    const migration = new ExcelMigration()
    migration.testCustomersOnly().catch(console.error)
  } else {
    console.log('üöÄ Starting Excel to Supabase Migration...')
    const migration = new ExcelMigration()
    migration.migrateAll().catch(console.error)
  }
}

// Export for use as module
module.exports = ExcelMigration
